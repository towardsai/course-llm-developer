{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/towardsai/course-llm-developer-8h/blob/main/notebooks/image-generation-and-speech-models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"your_openai_api_key_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api.openai.com/v1/images/generations\"\n",
    "\n",
    "# Create a user prompt with the user's question\n",
    "prompt = f\"A computer scientist wearing a coat implementing a neural network while sitting behind a computer\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"dall-e-3\",\n",
    "    \"prompt\": prompt,\n",
    "    \"size\":\"1024x1024\",\n",
    "    \"quality\":\"standard\",\n",
    "    \"n\":1,\n",
    "}\n",
    "\n",
    "# Set headers with API key\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(API_URL, json=payload, headers=headers)\n",
    "\n",
    "response = response.json()\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Fetch the image\n",
    "response = requests.get(response['data'][0]['url'])\n",
    "\n",
    "# Open the image with Pillow\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Speech Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api.openai.com/v1/audio/speech\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"tts-1\",\n",
    "    \"input\": \"Artificial Intelligence is the future!\",\n",
    "    \"voice\": \"alloy\"\n",
    "  }\n",
    "\n",
    "# Set headers with API key\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(API_URL, json=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "# Generating a unique file name for the output MP3 file\n",
    "save_file_path = \"voice.mp3\"\n",
    "\n",
    "# Writing the audio to a file\n",
    "with open(save_file_path, \"wb\") as f:\n",
    "    for chunk in response:\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "\n",
    "print(f\"{save_file_path}: A new audio file was saved successfully!\")\n",
    "\n",
    "display(Audio(save_file_path, autoplay=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
